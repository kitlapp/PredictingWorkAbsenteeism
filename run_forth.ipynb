{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f4598d-0fe8-476b-a25d-141005083472",
   "metadata": {},
   "source": [
    "# Logistic Regression Model for Human Resources Management "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631a72cb-eb76-40d8-9c64-a9d4bd7eccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.executable  # Display the path to the Python executable ensuring the correct env\"\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eedf6c-061f-4239-a46d-ac0817c6bf81",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e6ad7-996b-4851-ae04-d659c2f04445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For numerical operations and arrays.\t\n",
    "import pandas as pd  # For data manipulation and analysis.\t\n",
    "import matplotlib.pyplot as plt  # For basic plotting.\t\n",
    "import seaborn as sns  # For enhanced plotting.\t\n",
    "from sklearn.preprocessing import StandardScaler  # For creating scaler instances for standardization purposes.\n",
    "from sklearn.model_selection import train_test_split  # For splitting the data into sets avoiding overfitting.\n",
    "from sklearn.linear_model import LogisticRegression  # For creating LogisticRegression instances.\n",
    "from sklearn import metrics  # For evaluating the model\n",
    "from python_scripts import *\n",
    "from sklearn.model_selection import GridSearchCV  # For searching the best parameters over specified parameter values\n",
    "import joblib  # For saving models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8929705-769c-419d-94a5-d2f692281ce0",
   "metadata": {},
   "source": [
    "# Load Cleaned New Data, Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137613c-3307-412b-9fa6-a3e1c1e1d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV Datafile to a DataFrame:\n",
    "new_data = pd.read_csv('unseen_cleaned.csv')\n",
    "\n",
    "# Load the saved model and scaler\n",
    "filename = 'model.joblib'\n",
    "scalername = 'scaler.joblib'\n",
    "\n",
    "model = joblib.load(filename)\n",
    "scaler = joblib.load(scalername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81585794-84b5-4f9c-b6d7-0e486cabef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6d2e4-513e-4d9b-b802-9661d127a8dd",
   "metadata": {},
   "source": [
    "# Properly Use Saved Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f5064-f764-4a0d-b5f7-10bfb435655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose features to be scaled (these should match the features used when training the model)\n",
    "scale_not_all = ['Transportation Expense', 'Age', 'Body Mass Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160600e7-fda4-4c38-9481-761e1e6f2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same scaling to the new data\n",
    "new_data[scale_not_all] = scaler.transform(new_data[scale_not_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53f046-10e8-4c41-84bc-b63c85fb0f34",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01867d-1a8e-4623-aff6-b1520b4d6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the loaded model\n",
    "predictions = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591c210-b2d9-4909-8d17-8ad1382331f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e1b88-07e0-46ff-b4d0-258175f73497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, you can also get the predicted probabilities\n",
    "predicted_probabilities = model.predict_proba(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0bb23-4d1f-4356-aefc-5dbe32fc82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function to add results in the new data DataFrame:\n",
    "test_results_df = summary_metrics_on_new_data(new_data_df=new_data, \n",
    "                                              predictions=predictions, \n",
    "                                              pred_probabilities=predicted_probabilities)\n",
    "test_results_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
