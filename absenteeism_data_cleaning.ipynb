{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d217f7-0b3d-4454-adf4-1877ce2da665",
   "metadata": {},
   "source": [
    "# Environment Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087ea55-d885-4507-9539-790560cf24c8",
   "metadata": {},
   "source": [
    "**Environment Name:** Absenteeism   \n",
    "**Project Directory Name:** absenteeism_prj\n",
    "<div style=\"text-align: justify\">\n",
    "<strong>Original Imported Libraries and Python:</strong>  \n",
    "    \n",
    "-python=3.12.4 (from conda-forge)  \n",
    "-numpy=2.0.0 (from conda-forge)  \n",
    "-matplotlib=3.9.1 (from conda-forge)  \n",
    "-seaborn=0.13.2 (from conda-forge)  \n",
    "-pandas=2.2.2 (from conda-forge)  \n",
    "    \n",
    "<strong>Project Date:</strong> August 2024\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925eae36-6008-46b2-a5fd-d7cfbb5978ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.executable  # Display the path to the Python executable ensuring the correct env\"\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c929d59-3411-44b0-804c-702b753b18b7",
   "metadata": {},
   "source": [
    "# Import Libraries and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9282f117-ea19-4d01-a483-bf2a13a9c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For numerical operations and arrays.\t\n",
    "import pandas as pd  # For data manipulation and analysis.\t\n",
    "import matplotlib.pyplot as plt  # For basic plotting.\t\n",
    "import seaborn as sns  # For enhanced plotting.\t\n",
    "from absenteeism_scripts import range_monthdays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191f950a-7a8e-4f17-b142-c875746211c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV Datafile to a DataFrame:\n",
    "raw_data = pd.read_csv('Absenteeism_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04627c08-7828-4921-8412-695314e74805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061c039-c660-4811-9d58-164f3640f247",
   "metadata": {},
   "source": [
    "# Quick Data Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c67b84-541a-4a7f-b1d1-5311ae206977",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The target variable is the 'Absenteeism Time in Hours' column. The unique identifier is the 'ID' column. There is also a 'Date' column. The rest of the columns are features which will define the target variable. The Date column could be a trap because further analyzing it into weekdays might reveal a pattern about a specific weekday. Turning the Date column to weekdays instead of dates could make the column ideal for analysis. If not doing so, the Date column should also be dropped.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d3e89-de1b-4289-9993-83f8274db5c1",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9da77-ad14-45b6-81c1-20d30556d5d4",
   "metadata": {},
   "source": [
    "## Date Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953dd4c-f4a3-45a9-be6f-d14e913cb285",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "We 'll create more features from 'Date' column and we 'll let the model decide in next sections of this project whether these features are important or not.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1681e953-bbb8-450f-8bad-cd52cab92096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint:\n",
    "df_date = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de71282-4921-47f4-90ea-8f34f5f92b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime type:\n",
    "df_date['Date'] = pd.to_datetime(df_date['Date'], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Extract the weekday and adjust to (1=Monday,..., 6=Weekend):\n",
    "df_date['Weekday'] = df_date['Date'].dt.weekday.apply(lambda x: x + 1 if x < 5 else 6) \n",
    "\n",
    "# Extract the month and monthday from 'Date' column:\n",
    "df_date['Month'] = df_date['Date'].dt.month \n",
    "df_date['Monthday'] = df_date['Date'].dt.day\n",
    "\n",
    "# Apply function to range the monthdays into 6 categories:\n",
    "df_date['Monthday'] = df_date['Monthday'].apply(range_monthdays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48164394-2705-4a67-9601-7a144d6085a8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "We could drop the 13 rows that represent weekend absences because it's likely that there were not many people working on weekends. This fact might introduce noise and potentially degrade our analysis. However, we will keep the initial number of observations intact for now. If the model weights indicate that the 'Monthday' column plays a crucial role in our analysis, we can revisit this decision and delete these 13 rows to see the impact. However, if the 'Monthday' column is unimportant for our analysis, dropping these 13 observations will be unnecessary and have no meaningful effect on the analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c114bf6-2205-4228-ad42-e948796f25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'Date' column:\n",
    "df_date = df_date.drop(columns='Date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e687e4e-724d-4458-8eda-87ddcd23a651",
   "metadata": {},
   "source": [
    "## ID Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf56f94a-8ea1-4bdd-bd68-760046db43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint:\n",
    "df_id = df_date.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b0f113b-7d45-4a1d-a018-c84b97c022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'ID' column:\n",
    "df_id = df_id.drop(columns='ID', axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3405d-1633-4200-9976-48fbff3f3d19",
   "metadata": {},
   "source": [
    "## Reason for Absence Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378fbe5e-31e6-4aa9-94a6-9692e06b4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint:\n",
    "df_reason_for_absence = df_id.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddbff58-1f15-4bbd-ab01-fcd10d7c2fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode 'Reason for Absence' and ensure single reason per row:\n",
    "reason_for_absence = pd.get_dummies(df_reason_for_absence['Reason for Absence']).astype(int)\n",
    "reason_for_absence.sum(axis=1).unique()  # This should return array([1]) if each absence has only one reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bca87-3815-48cb-a904-7cf80b15d942",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "We executed the cells above only to ensure that there is only one single reason for each absence. After checking this, we should one-hot-encode the 'Reason for Absence' column correctly, dropping the first column to prevent multicollinearity.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75822d39-2441-4c96-ad73-fd18891d2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'Reason for Absence' column:\n",
    "df_reason_for_absence = df_reason_for_absence.drop(columns='Reason for Absence', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734ea16-eaa6-4b20-8d90-43fac1fcc223",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "We can group the reason_for_absence DataFrame into larger groups related to the reason someone is absent from work. For example, there are 14 reasons (Number 1 to 14) which are related to diseases, 3 reasons related to pregnancy (Number 15 to 17), 4 reasons related to other important factors influencing health (Number 18 to 21), and the final 7 reasons (Number 22 to 28) are not related to major health issues but to preventive medicine, recovery from a disease, unjustified absence, etc. This is inside information that I can't share with you because I don't own it either. Although we defined 4 major categories inside the 'Reason for Absence' column, our final number of groups will be 3: Disease, Pregnancy or Other Factors, and Not-Major Health reasons.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c397496f-a6f1-4484-b12b-5ccd6dbc3ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate absence reasons into broader categories:\n",
    "disease = reason_for_absence.loc[:, 0:14].sum(axis=1)  # Disease reasons\n",
    "pregnancy = reason_for_absence.loc[:, 15:17].sum(axis=1)  # Pregnancy reasons\n",
    "other_factors = reason_for_absence.loc[:, 18:21].sum(axis=1)  # Other important reasons\n",
    "not_major_health_issues = reason_for_absence.loc[:, 22:28].sum(axis=1)  # Not major reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "914b4340-309a-4933-8dc0-82e2e5d76a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the newly created Series with the main DataFrame:\n",
    "df_reason_for_absence = pd.concat(\n",
    "    [df_reason_for_absence, disease, pregnancy, other_factors, not_major_health_issues], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d7cfca1-4fb7-47f8-bd8a-14a449ebcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct column names:\n",
    "corrected_column_names = ['Transportation Expense', 'Distance to Work', 'Age', 'Daily Work Load Average', \n",
    "                          'Body Mass Index', 'Education', 'Children', 'Pets', 'Absenteeism Time in Hours', \n",
    "                          'Weekday Absence Occurred', 'Month Absence Occurred', 'Monthday Range Absence Occurred', \n",
    "                          'Disease Absence', 'Pregnancy Absence', 'Other Factor Absence', 'Not-Major Issue Absence']\n",
    "\n",
    "# Assign the corrected column names to the main DataFrame:\n",
    "df_reason_for_absence.columns = corrected_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0728aea-5beb-4bd8-96a0-3669058d3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the least impactful column to prevent multicollinearity:\n",
    "df_reason_for_absence = df_reason_for_absence.drop(columns='Pregnancy Absence')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa996bc-9ea1-4483-bcad-25c8e65b6295",
   "metadata": {},
   "source": [
    "## Education Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd22d4f8-a50b-458a-a9f7-729c5a32a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint:\n",
    "df_education = df_reason_for_absence.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b04399-32d5-4a0f-a35b-bb223fd3744b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The Education column takes values from 1 to 4, where 1 represents high school education, 2 represents graduate education, 3 represents postgraduate education, and 4 represents a master's degree or PhD. The issue is that individuals with a high school education (1) constitute 83.3% of the dataset, while the remaining three categories together account for the rest. To enhance the impact of the education column, we will combine categories 2, 3, and 4 into a single category representing education levels higher than high school.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8bed5-3b07-4d66-a086-8f73d0624be2",
   "metadata": {},
   "source": [
    "Therefore we 'll create these groups:  \n",
    "1) 0: High School Education\n",
    "2) 1: Higher than High School Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af538f5c-6d3a-43df-8da1-7152b76b5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify 'Education' column into two categories:\n",
    "df_education['Education'] = df_education['Education'].apply(lambda x: 0 if x==1 else 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab064f-3c18-433a-9539-61fe2b05b515",
   "metadata": {},
   "source": [
    "## Children Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce1614a6-fa34-4a16-a9cc-48e55836e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint:\n",
    "df_children = df_education.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e98bb-16d3-4ccb-850c-bf5c5174daff",
   "metadata": {},
   "source": [
    "Here we 'll create these groups:  \n",
    "1) 0: Zero Children\n",
    "2) 1: One Children\n",
    "3) 2: Two Children\n",
    "4) 3: More than Two Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7e15dfc-3b47-41df-935e-bd009c3e663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'Children' into categories and one-hot encode:\n",
    "df_children['Children'] = df_children['Children'].apply(lambda x: x if x <= 2 else 3)\n",
    "children_dummies = pd.get_dummies(df_children['Children'], drop_first=True).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19964c59-85bc-4247-8dcb-f23e6ea50bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Name the dummies properly:\n",
    "children_dummies['Has 1 Child'] = children_dummies[1]\n",
    "children_dummies['Has 2 Children'] = children_dummies[2]\n",
    "children_dummies['Has More than 2 Children'] = children_dummies[3]\n",
    "\n",
    "# Drop the initial columns:\n",
    "children_dummies = children_dummies.drop(columns=[1, 2, 3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd8e90c2-25bd-4efb-bd3e-dc24c2790ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Children' column from main DataFrame:\n",
    "df_children = df_children.drop(columns='Children', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1315efa-b3bd-4884-a09c-ca364ec4f8c8",
   "metadata": {},
   "source": [
    "## Pet Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd76de1a-242e-49f4-a280-c61714308504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint:\n",
    "df_pet = df_children.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191dfed-9b88-40c7-9f1e-ceaa98009017",
   "metadata": {},
   "source": [
    "Here we 'll create these groups:  \n",
    "1) 0: Zero Pets\n",
    "2) 1: One Pet\n",
    "3) 2: Two Pets\n",
    "4) 3: More than Two Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a47a5954-bb6c-4fd1-8b07-a1850c7554c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'Pets' into categories and one-hot encode:\n",
    "df_pet['Pets'] = df_pet['Pets'].apply(lambda x: x if x <= 2 else 3)\n",
    "pet_dummies = pd.get_dummies(df_pet['Pets'], drop_first=True).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1be909b5-88c4-4d64-a4b1-76f4801fb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the dummies properly:\n",
    "pet_dummies['Has 1 Pet'] = pet_dummies[1]\n",
    "pet_dummies['Has 2 Pets'] = pet_dummies[2]\n",
    "pet_dummies['Has More than 2 Pets'] = pet_dummies[3]\n",
    "\n",
    "# Drop the initial columns:\n",
    "pet_dummies = pet_dummies.drop(columns=[1, 2, 3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03178aa7-465a-46cb-84a5-21729237354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Pets' column from main DataFrame:\n",
    "df_pet = df_pet.drop(columns='Pets', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7a51d-37e2-493e-98d7-51e9a7982c62",
   "metadata": {},
   "source": [
    "***This is the End of Feature Preprocessing***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5162c9d-f994-4932-96ec-5acdedd66712",
   "metadata": {},
   "source": [
    "# Target Classification for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536c205-ca11-44fe-86ee-00c59cf9c66a",
   "metadata": {},
   "source": [
    "We 'll modify the target variable for a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "372bf97a-1580-43a5-98d9-ac09dbe24fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint:\n",
    "df_target = df_pet.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43679d7b-4694-4a99-87a1-acfffb465cda",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "We have only 700 observations, and an ideal approach to separate the target values into binary classes without affecting balance and/or losing observations is by using the median. The median will ideally separate the data into two equal sets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3843a468-b6ae-4364-b6b2-b857f7ce6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate target's median:\n",
    "median = df_target['Absenteeism Time in Hours'].median()\n",
    "\n",
    "# Apply median to create binary target values:\n",
    "df_target['Absenteeism Time in Hours'] = df_target['Absenteeism Time in Hours'].apply(\n",
    "    lambda x: 0 if x <= median else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8490b1-f750-4ba5-a130-05b6ec7767b8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The target column is not perfectly balanced after median separation, but using the value_counts method indicates that the two new classes are separated into 46-54% observations. This is within the limit for a set to be characterized as balanced, even for a neural network model, which is stricter than a logistic regression model in terms of balanced sets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd442b23-cf69-4363-9d82-85fc7ea97678",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The new target column has values of 0s and 1s. Interpreting the 0s, we should note that '0' doesn't mean a person wasn't absent from work but that there wasn't an extensive absence. On the other hand, '1' means there was extensive absence. For this reason, we will change the name of the target column for interpretability reasons to 'Extensive Absenteeism Time in Hours'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1c1ff50-dae5-4c81-a7a9-349565f5fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the target column to 'Extensive Absenteeism Time in Hours' for better interpretability:\n",
    "df_target['Extensive Absenteeism Time in Hours'] = df_target['Absenteeism Time in Hours']\n",
    "\n",
    "# Drop 'Absenteeism Time in Hours' column from main DataFrame:\n",
    "df_target = df_target.drop(columns='Absenteeism Time in Hours', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd81f7-f427-4654-9581-1a413bfa488b",
   "metadata": {},
   "source": [
    "***This is the End of Target Preprocessing***  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a024e-a883-4cd2-b6b9-1598122ee9d6",
   "metadata": {},
   "source": [
    "# Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcc072c4-6b64-48c1-a749-1ae71e738aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint\n",
    "df_final = df_target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccc779a2-827e-4fbb-b378-cfc1af46d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the newly created Series with the main DataFrame:\n",
    "df_final = pd.concat(\n",
    "    [df_target, children_dummies, pet_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06310ec1-ce3f-4a25-96ac-8e0c40058589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Transportation Expense', 'Distance to Work', 'Age',\n",
       "       'Daily Work Load Average', 'Body Mass Index', 'Education',\n",
       "       'Weekday Absence Occurred', 'Month Absence Occurred',\n",
       "       'Monthday Range Absence Occurred', 'Disease Absence',\n",
       "       'Other Factor Absence', 'Not-Major Issue Absence',\n",
       "       'Extensive Absenteeism Time in Hours', 'Has 1 Child',\n",
       "       'Has 2 Children', 'Has More than 2 Children', 'Has 1 Pet',\n",
       "       'Has 2 Pets', 'Has More than 2 Pets'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "242660ea-84dd-4bfe-b46e-c365d5823b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder column names:\n",
    "reordered_cols_list = ['Month Absence Occurred', 'Monthday Range Absence Occurred', 'Weekday Absence Occurred', \n",
    "                       'Disease Absence', 'Other Factor Absence', 'Not-Major Issue Absence', 'Education', \n",
    "                       'Has 1 Child', 'Has 2 Children', 'Has More than 2 Children', 'Has 1 Pet', 'Has 2 Pets', \n",
    "                       'Has More than 2 Pets', 'Transportation Expense', 'Distance to Work', 'Age', \n",
    "                       'Daily Work Load Average', 'Body Mass Index', 'Extensive Absenteeism Time in Hours']\n",
    "\n",
    "# Assign the reordered column to the main DataFrame:\n",
    "df_final = df_final[reordered_cols_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04dc956-4680-4258-bc56-72350c0cba57",
   "metadata": {},
   "source": [
    "## Export Cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a44c3c5f-4520-4c72-b6c2-3922bfe8a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned DataFrame to a CSV file:\n",
    "df_final.to_csv('cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
